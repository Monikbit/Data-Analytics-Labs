{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='orange'> Lab | Web Scraping Multiple Pages  </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Business goal:\n",
    "- Check the case_study_gnod.md file.\n",
    "- Make sure you've understood the big picture of your project:\n",
    "- the goal of the company (Gnod),\n",
    "- their current product (Gnoosic),\n",
    "- their strategy, and\n",
    "- how your project fits into this context.\n",
    "- Re-read the business case and the e-mail from the CTO, take a look at the flowchart and create an initial Trello board with the tasks you think you'll have to accomplish.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instructions\n",
    "  - Prioritize the MVP\n",
    "  - In the previous lab, you had to scrape data about \"hot songs\". It's critical to be on track with that part, as it was part of the request from the CTO.\n",
    "  - If you couldn't finish the first lab, use this time to go back there.\n",
    "  - Expand the project\n",
    "  - If you're done, you can try to expand the project on your own. Here are a few suggestions:\n",
    "  - Find other lists of hot songs on the internet and scrape them too: having a bigger pool of songs will be awesome!\n",
    "  - Apply the same logic to other \"groups\" of songs: the best songs from a decade or from a country / culture / language / genre.\n",
    "  - Wikipedia maintains a large collection of lists of songs: https://en.wikipedia.org/wiki/Lists_of_songs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Enlace trello \n",
    "https://trello.com/invite/b/NdM54rFw/ATTI63ea383c365c9d6f9c23698cc7321976C345E061/gnoosic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1581,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos traemos lo del lab anterior\n",
    "url = 'https://www.billboard.com/charts/hot-100/'\n",
    "billboard_html = requests.get(url).content\n",
    "soup = BeautifulSoup(billboard_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boy's A Liar, Pt. 2</td>\n",
       "      <td>PinkPantheress &amp; Ice Spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creepin'</td>\n",
       "      <td>Metro Boomin, The Weeknd &amp; 21 Savage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Slut Me Out</td>\n",
       "      <td>NLE Choppa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>La Jumpa</td>\n",
       "      <td>Arcangel &amp; Bad Bunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shut Up My Moms Calling</td>\n",
       "      <td>Hotel Ugly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Gold</td>\n",
       "      <td>Dierks Bentley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Back End</td>\n",
       "      <td>Finesse2Tymes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       song                                artist\n",
       "0                   Flowers                           Miley Cyrus\n",
       "1                 Kill Bill                                   SZA\n",
       "2       Boy's A Liar, Pt. 2            PinkPantheress & Ice Spice\n",
       "3                  Creepin'  Metro Boomin, The Weeknd & 21 Savage\n",
       "4                Last Night                         Morgan Wallen\n",
       "..                      ...                                   ...\n",
       "95              Slut Me Out                            NLE Choppa\n",
       "96                 La Jumpa                  Arcangel & Bad Bunny\n",
       "97  Shut Up My Moms Calling                            Hotel Ugly\n",
       "98                     Gold                        Dierks Bentley\n",
       "99                 Back End                         Finesse2Tymes\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 1583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = soup.find_all(\"h3\", class_=\"a-no-trucate\")\n",
    "artists = soup.find_all(\"span\", class_=\"a-no-trucate\")\n",
    "for i in [songs, artists]:\n",
    "    for j in range(len(i)):\n",
    "        i[j] = i[j].getText()\n",
    "billboard = pd.DataFrame(\n",
    "    {\"song\": songs,\n",
    "     \"artist\": artists})\n",
    "billboard= billboard.replace({'\\n':'','\\t':'' }, regex=True)\n",
    "billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontramos una nueva lista con top 200 \n",
    "url = 'https://kworb.net/spotify/country/global_daily.html'\n",
    "spotify_chart = requests.get(url).content\n",
    "soup = BeautifulSoup(spotify_chart, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1585,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = soup.select('div>a') # Nos va a traer el artista y la cancion\n",
    "artists = search[::2]\n",
    "songs = search[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Get the text\n",
    "for i in [artists, songs]:\n",
    "    for j in range(len(i)):\n",
    "        i[j] = i[j].getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songs</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TQG</td>\n",
       "      <td>KAROL G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die For You - Remix</td>\n",
       "      <td>The Weeknd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boy's a liar Pt. 2</td>\n",
       "      <td>PinkPantheress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>STAR WALKIN' (League of Legends Worlds Anthem)</td>\n",
       "      <td>Lil Nas X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>After Hours</td>\n",
       "      <td>The Weeknd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Locked out of Heaven</td>\n",
       "      <td>Bruno Mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Payphone</td>\n",
       "      <td>Maroon 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>One Kiss</td>\n",
       "      <td>Calvin Harris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              songs          artist\n",
       "0                                           Flowers     Miley Cyrus\n",
       "1                                               TQG         KAROL G\n",
       "2                                         Kill Bill             SZA\n",
       "3                               Die For You - Remix      The Weeknd\n",
       "4                                Boy's a liar Pt. 2  PinkPantheress\n",
       "..                                              ...             ...\n",
       "195  STAR WALKIN' (League of Legends Worlds Anthem)       Lil Nas X\n",
       "196                                     After Hours      The Weeknd\n",
       "197                            Locked out of Heaven      Bruno Mars\n",
       "198                                        Payphone        Maroon 5\n",
       "199                                        One Kiss   Calvin Harris\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 1587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top200 = pd.DataFrame({\"songs\": songs,\"artist\": artists })\n",
    "top200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of anti-war songs\n",
    "# General pacifist and anti-war songs\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_anti-war_songs'\n",
    "anti_war = requests.get(url).content\n",
    "soup = BeautifulSoup(anti_war, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1971</td>\n",
       "      <td>And the Band Played Waltzing Matilda</td>\n",
       "      <td>Eric Bogle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1867</td>\n",
       "      <td>Johnny I Hardly Knew Ye</td>\n",
       "      <td>Traditional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>19</td>\n",
       "      <td>Paul Hardcastle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1966</td>\n",
       "      <td>7 O'Clock News/Silent Night</td>\n",
       "      <td>Simon &amp; Garfunkel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1989</td>\n",
       "      <td>After the War</td>\n",
       "      <td>Gary Moore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1976</td>\n",
       "      <td>Zombie</td>\n",
       "      <td>Fela Kuti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1994</td>\n",
       "      <td>Zombie</td>\n",
       "      <td>The Cranberries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1968</td>\n",
       "      <td>Zor and Zam</td>\n",
       "      <td>The Monkees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1982</td>\n",
       "      <td>Радиоактивность (Radioactivity)</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1999</td>\n",
       "      <td>Il mio nome è mai più</td>\n",
       "      <td>LigaJovaPelù (Luciano Ligabue, Jovanotti, Pier...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year                                  song  \\\n",
       "0    1971  And the Band Played Waltzing Matilda   \n",
       "1    1867               Johnny I Hardly Knew Ye   \n",
       "2    1985                                    19   \n",
       "3    1966           7 O'Clock News/Silent Night   \n",
       "4    1989                         After the War   \n",
       "..    ...                                   ...   \n",
       "300  1976                                Zombie   \n",
       "301  1994                                Zombie   \n",
       "302  1968                           Zor and Zam   \n",
       "303  1982       Радиоактивность (Radioactivity)   \n",
       "304  1999                 Il mio nome è mai più   \n",
       "\n",
       "                                                artist  \n",
       "0                                           Eric Bogle  \n",
       "1                                          Traditional  \n",
       "2                                      Paul Hardcastle  \n",
       "3                                    Simon & Garfunkel  \n",
       "4                                           Gary Moore  \n",
       "..                                                 ...  \n",
       "300                                          Fela Kuti  \n",
       "301                                    The Cranberries  \n",
       "302                                        The Monkees  \n",
       "303                                             Center  \n",
       "304  LigaJovaPelù (Luciano Ligabue, Jovanotti, Pier...  \n",
       "\n",
       "[305 rows x 3 columns]"
      ]
     },
     "execution_count": 1589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search=soup.select('td')\n",
    "search = [i.get_text() for i in search]\n",
    "search=search[2:917]\n",
    "year=search[0::3]\n",
    "song=search[1::3]\n",
    "artist = search[2::3]\n",
    "anti_war_songs=pd.DataFrame({'year': year,\n",
    "                             'song': song,\n",
    "                             'artist':artist})\n",
    "anti_war_songs=anti_war_songs.replace({'\"':'','\\n':''}, regex=True)\n",
    "anti_war_songs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='orange'> Practice web scraping  </font>\n",
    "- As you've seen, scraping the internet is a skill that can get you all sorts of information. Here are some little challenges that you can try to gain more experience in the field:\n",
    "- Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links on that page: url ='https://en.wikipedia.org/wiki/Python'\n",
    "- Find the number of titles that have changed in the United States Code since its last release point: url = 'http://uscode.house.gov/download/download.shtml'\n",
    "- Create a Python list with the top ten FBI's Most Wanted names: url = 'https://www.fbi.gov/wanted/topten'\n",
    "- Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe: url = 'https://www.emsc-csem.org/Earthquake/'\n",
    "- List all language names and number of related articles in the order they appear in wikipedia.org: url = 'https://www.wikipedia.org/'\n",
    "- A list with the different kind of datasets available in data.gov.uk: url = 'https://data.gov.uk/'\n",
    "- Display the top 10 languages by number of native speakers stored in a pandas dataframe: url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links on that page:\n",
    "url ='https://en.wikipedia.org/wiki/Python'\n",
    "python_links = requests.get(url).content\n",
    "soup = BeautifulSoup(python_links, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1591,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for link in soup.find_all(\"a\"):\n",
    "    href = link.get(\"href\")\n",
    "    if href.startswith(\"http\"):\n",
    "        links.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452',\n",
       " 'https://commons.wikimedia.org/wiki/Category:Python',\n",
       " 'https://af.wikipedia.org/wiki/Python',\n",
       " 'https://als.wikipedia.org/wiki/Python',\n",
       " 'https://ar.wikipedia.org/wiki/%D8%A8%D8%A7%D9%8A%D8%AB%D9%88%D9%86_(%D8%AA%D9%88%D8%B6%D9%8A%D8%AD)',\n",
       " 'https://az.wikipedia.org/wiki/Python_(d%C9%99qiql%C9%99%C5%9Fdirm%C9%99)',\n",
       " 'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8_(%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%8D%E0%A6%AF%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%A4%E0%A6%BE_%E0%A6%A8%E0%A6%BF%E0%A6%B0%E0%A6%B8%E0%A6%A8)',\n",
       " 'https://be.wikipedia.org/wiki/Python',\n",
       " 'https://bg.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%BF%D0%BE%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)',\n",
       " 'https://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)',\n",
       " 'https://da.wikipedia.org/wiki/Python',\n",
       " 'https://de.wikipedia.org/wiki/Python',\n",
       " 'https://eo.wikipedia.org/wiki/Pitono_(apartigilo)',\n",
       " 'https://eu.wikipedia.org/wiki/Python_(argipena)',\n",
       " 'https://fa.wikipedia.org/wiki/%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86',\n",
       " 'https://fr.wikipedia.org/wiki/Python',\n",
       " 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%84%A0',\n",
       " 'https://hr.wikipedia.org/wiki/Python_(razdvojba)',\n",
       " 'https://io.wikipedia.org/wiki/Pitono',\n",
       " 'https://id.wikipedia.org/wiki/Python',\n",
       " 'https://ia.wikipedia.org/wiki/Python_(disambiguation)',\n",
       " 'https://is.wikipedia.org/wiki/Python_(a%C3%B0greining)',\n",
       " 'https://it.wikipedia.org/wiki/Python_(disambigua)',\n",
       " 'https://he.wikipedia.org/wiki/%D7%A4%D7%99%D7%AA%D7%95%D7%9F',\n",
       " 'https://ka.wikipedia.org/wiki/%E1%83%9E%E1%83%98%E1%83%97%E1%83%9D%E1%83%9C%E1%83%98_(%E1%83%9B%E1%83%A0%E1%83%90%E1%83%95%E1%83%90%E1%83%9A%E1%83%9B%E1%83%9C%E1%83%98%E1%83%A8%E1%83%95%E1%83%9C%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%90%E1%83%9C%E1%83%98)',\n",
       " 'https://kg.wikipedia.org/wiki/Mboma_(nyoka)',\n",
       " 'https://la.wikipedia.org/wiki/Python_(discretiva)',\n",
       " 'https://lb.wikipedia.org/wiki/Python',\n",
       " 'https://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)',\n",
       " 'https://mr.wikipedia.org/wiki/%E0%A4%AA%E0%A4%BE%E0%A4%AF%E0%A4%A5%E0%A5%89%E0%A4%A8_(%E0%A4%86%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%B5%E0%A4%B2%E0%A5%80_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE)',\n",
       " 'https://nl.wikipedia.org/wiki/Python',\n",
       " 'https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%82%BD%E3%83%B3',\n",
       " 'https://no.wikipedia.org/wiki/Pyton',\n",
       " 'https://pl.wikipedia.org/wiki/Pyton',\n",
       " 'https://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)',\n",
       " 'https://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)',\n",
       " 'https://sk.wikipedia.org/wiki/Python',\n",
       " 'https://sr.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%B2%D0%B8%D1%88%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%BD%D0%B0_%D0%BE%D0%B4%D1%80%D0%B5%D0%B4%D0%BD%D0%B8%D1%86%D0%B0)',\n",
       " 'https://sh.wikipedia.org/wiki/Python',\n",
       " 'https://fi.wikipedia.org/wiki/Python',\n",
       " 'https://sv.wikipedia.org/wiki/Pyton',\n",
       " 'https://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9E%E0%B8%97%E0%B8%AD%E0%B8%99',\n",
       " 'https://tr.wikipedia.org/wiki/Python_(anlam_ayr%C4%B1m%C4%B1)',\n",
       " 'https://uk.wikipedia.org/wiki/%D0%9F%D1%96%D1%84%D0%BE%D0%BD',\n",
       " 'https://ur.wikipedia.org/wiki/%D9%BE%D8%A7%D8%A6%DB%8C%D8%AA%DA%BE%D9%88%D9%86',\n",
       " 'https://vi.wikipedia.org/wiki/Python',\n",
       " 'https://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452#sitelinks-wikipedia',\n",
       " 'https://en.wiktionary.org/wiki/Python',\n",
       " 'https://en.wiktionary.org/wiki/python',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&oldid=1139211777',\n",
       " 'https://foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " 'https://developer.wikimedia.org',\n",
       " 'https://stats.wikimedia.org/#/en.wikipedia.org',\n",
       " 'https://foundation.wikimedia.org/wiki/Cookie_statement',\n",
       " 'https://wikimediafoundation.org/',\n",
       " 'https://www.mediawiki.org/']"
      ]
     },
     "execution_count": 1592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links on that page:\n",
    "links=list(links)\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of titles that have changed in the United States Code since its last release point:\n",
    "url ='http://uscode.house.gov/download/download.shtml'\n",
    "titles_UE = requests.get(url).content\n",
    "soup = BeautifulSoup(titles_UE, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1594,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = soup.find_all(\"div\", class_=\"usctitlechanged\")\n",
    "titles = [i.get_text() for i in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1595,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Get the text\n",
    "# for i in [titles]:\n",
    "#     for j in range(len(i)):\n",
    "#         i[j] = i[j].getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1596,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=list(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title 2 - The Congress',\n",
       " 'Title 3 - The President',\n",
       " 'Title 5 - Government Organization and Employees',\n",
       " 'Title 6 - Domestic Security',\n",
       " 'Title 7 - Agriculture',\n",
       " 'Title 8 - Aliens and Nationality',\n",
       " 'Title 10 - Armed Forces',\n",
       " 'Title 12 - Banks and Banking',\n",
       " 'Title 14 - Coast Guard',\n",
       " 'Title 15 - Commerce and Trade',\n",
       " 'Title 16 - Conservation',\n",
       " 'Title 18 - Crimes and Criminal Procedure',\n",
       " 'Title 19 - Customs Duties',\n",
       " 'Title 20 - Education',\n",
       " 'Title 21 - Food and Drugs',\n",
       " 'Title 22 - Foreign Relations and Intercourse',\n",
       " 'Title 23 - Highways',\n",
       " 'Title 24 - Hospitals and Asylums',\n",
       " 'Title 25 - Indians',\n",
       " 'Title 26 - Internal Revenue Code',\n",
       " 'Title 29 - Labor',\n",
       " 'Title 30 - Mineral Lands and Mining',\n",
       " 'Title 31 - Money and Finance',\n",
       " 'Title 33 - Navigation and Navigable Waters',\n",
       " 'Title 34 - Crime Control and Law Enforcement',\n",
       " 'Title 35 - Patents',\n",
       " 'Title 36 - Patriotic and National Observances, Ceremonies, and Organizations',\n",
       " \"Title 38 - Veterans' Benefits\",\n",
       " 'Title 39 - Postal Service',\n",
       " 'Title 40 - Public Buildings, Property, and Works',\n",
       " 'Title 41 - Public Contracts',\n",
       " 'Title 42 - The Public Health and Welfare',\n",
       " 'Title 43 - Public Lands',\n",
       " 'Title 44 - Public Printing and Documents',\n",
       " 'Title 45 - Railroads',\n",
       " 'Title 46 - Shipping',\n",
       " 'Title 47 - Telecommunications',\n",
       " 'Title 48 - Territories and Insular Possessions',\n",
       " 'Title 49 - Transportation',\n",
       " 'Title 50 - War and National Defense',\n",
       " 'Title 51 - National and Commercial Space Programs',\n",
       " 'Title 54 - National Park Service and Related Programs']"
      ]
     },
     "execution_count": 1597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [x.replace('\\n', '').replace('٭','').strip() for x in titles]\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1599,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Python list with the top ten FBI's Most Wanted names:\n",
    "url = 'https://www.fbi.gov/wanted/topten'\n",
    "fbi_mw = requests.get(url).content\n",
    "soup = BeautifulSoup(fbi_mw, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most_wanted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOSE RODOLFO VILLARREAL HERNANDEZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALEJANDRO ROSALES CASTILLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YULAN ADONAY ARCHAGA CARIAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RUJA IGNATOVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARNOLDO JIMENEZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OMAR ALEXANDER CARDENAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ALEXIS FLORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BHADRESHKUMAR CHETANBHAI PATEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MICHAEL JAMES PRATT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RAFAEL CARO QUINTERO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         most_wanted\n",
       "0  JOSE RODOLFO VILLARREAL HERNANDEZ\n",
       "1         ALEJANDRO ROSALES CASTILLO\n",
       "2        YULAN ADONAY ARCHAGA CARIAS\n",
       "3                      RUJA IGNATOVA\n",
       "4                    ARNOLDO JIMENEZ\n",
       "5            OMAR ALEXANDER CARDENAS\n",
       "6                      ALEXIS FLORES\n",
       "7     BHADRESHKUMAR CHETANBHAI PATEL\n",
       "8                MICHAEL JAMES PRATT\n",
       "9               RAFAEL CARO QUINTERO"
      ]
     },
     "execution_count": 1600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbi = soup.find_all(\"h3\", class_='title' )\n",
    "fbi = [i.get_text() for i in fbi]\n",
    "fbi=pd.DataFrame({\"most_wanted\":fbi})\n",
    "fbi=fbi.replace({'\\n':'','-':' ' }, regex=True)\n",
    "fbi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1601,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe: \n",
    "url = 'https://www.emsc-csem.org/Earthquake/'\n",
    "earthquakes = requests.get(url).content\n",
    "soup = BeautifulSoup(earthquakes, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1602,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time=soup.select(\"b>a\")\n",
    "date_time = [i.get_text() for i in date_time]\n",
    "date_time = [x.replace(\"\\xa0\\xa0\\xa0\", \" \") for x in date_time]\n",
    "date_time = [x.split(\" \") for x in date_time]\n",
    "date_time.pop(50) # Eliminamos el elemento 50, ya que no es parte de la info que queremos  ['Privacy']]\n",
    "date_time=pd.DataFrame(date_time)\n",
    "date_time = date_time.set_axis(['date', 'time'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude\n",
    "lat_long=soup.find_all(\"td\", class_=\"tabev1\") # aqui nos esta dando primero latitud y luego longitud\n",
    "lat_long = [i.get_text() for i in lat_long]\n",
    "lat_long = [x.replace(\"\\xa0\", \"\") for x in lat_long]\n",
    "latitude = lat_long[0:100:2]\n",
    "longitude = lat_long[1:100:2]\n",
    "latitude= pd.DataFrame(latitude)\n",
    "longitude= pd.DataFrame(longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui no obtuvimos la longitud y latitud completa, falta traernos las columas dew si es N o S ,  E Y W\n",
    "lat_long_let=soup.find_all(\"td\", class_=\"tabev2\")  # Aqui tambien nos esta trayendo la magnitud\n",
    "lat_long_let=[i.get_text() for i in lat_long_let]\n",
    "lat_long_let=[x.replace(\"\\xa0\",\"\") for x in lat_long_let]\n",
    "lat_let = lat_long_let[0:150:3]\n",
    "lon_let = lat_long_let[1:150:3]\n",
    "magnitude = lat_long_let[2:150:3]\n",
    "lat_let= pd.DataFrame(lat_let)\n",
    "lon_let= pd.DataFrame(lon_let)\n",
    "magnitude= pd.DataFrame(magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1605,
   "metadata": {},
   "outputs": [],
   "source": [
    "region=soup.find_all(\"td\", class_=\"tb_region\")\n",
    "region = [i.get_text() for i in region] # aqui nos esta dando primero latitud y luego longitud\n",
    "region=[x.replace(\"\\xa0\",\"\") for x in region]\n",
    "region = pd.DataFrame(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un Dataframe con toda nuestra data\n",
    "data=np.concatenate([date_time, latitude, lat_let, longitude, lon_let, magnitude, region], axis=1, )\n",
    "data=pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>region</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>22:06:39.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "      <td>38.34 N</td>\n",
       "      <td>27.17 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>21:52:37.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>19.39 N</td>\n",
       "      <td>155.48 W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>21:49:59.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>CHINA-LAOS-VIETNAM BORDER REGION</td>\n",
       "      <td>22.28 N</td>\n",
       "      <td>102.28 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>21:49:22.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>37.39 N</td>\n",
       "      <td>36.90 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>21:35:51.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "      <td>38.99 N</td>\n",
       "      <td>27.85 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>21:31:53.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>37.48 N</td>\n",
       "      <td>37.13 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>21:18:41.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "      <td>38.79 N</td>\n",
       "      <td>122.78 W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>21:16:49.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "      <td>38.83 N</td>\n",
       "      <td>122.70 W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>21:13:20.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>SERAM, INDONESIA</td>\n",
       "      <td>3.35 S</td>\n",
       "      <td>128.35 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>21:11:06.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>41.36 N</td>\n",
       "      <td>19.59 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>20:56:52.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>37.99 N</td>\n",
       "      <td>36.42 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>20:55:28.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>VANUATU</td>\n",
       "      <td>14.86 S</td>\n",
       "      <td>166.88 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>20:52:01.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>38.16 N</td>\n",
       "      <td>37.89 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>20:37:10.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>37.61 N</td>\n",
       "      <td>37.19 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>20:25:10.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>MOLUCCA SEA</td>\n",
       "      <td>2.91 N</td>\n",
       "      <td>127.42 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>20:22:46.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>38.12 N</td>\n",
       "      <td>37.86 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>20:22:02.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>MOLUCCA SEA</td>\n",
       "      <td>0.29 N</td>\n",
       "      <td>125.74 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>20:16:45.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>38.03 N</td>\n",
       "      <td>36.65 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>20:11:50.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>38.09 N</td>\n",
       "      <td>37.89 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>20:00:02.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SANTA CRUZ ISLANDS</td>\n",
       "      <td>11.97 S</td>\n",
       "      <td>166.05 E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date        time magnitude                            region  \\\n",
       "0   2023-03-02  22:06:39.1       2.0                    WESTERN TURKEY   \n",
       "1   2023-03-02  21:52:37.9       2.1          ISLAND OF HAWAII, HAWAII   \n",
       "2   2023-03-02  21:49:59.0       4.5  CHINA-LAOS-VIETNAM BORDER REGION   \n",
       "3   2023-03-02  21:49:22.6       2.3                    CENTRAL TURKEY   \n",
       "4   2023-03-02  21:35:51.2       3.0                    WESTERN TURKEY   \n",
       "5   2023-03-02  21:31:53.1       2.2                    CENTRAL TURKEY   \n",
       "6   2023-03-02  21:18:41.7       2.2               NORTHERN CALIFORNIA   \n",
       "7   2023-03-02  21:16:49.8       3.2               NORTHERN CALIFORNIA   \n",
       "8   2023-03-02  21:13:20.0       3.7                  SERAM, INDONESIA   \n",
       "9   2023-03-02  21:11:06.5       2.0                           ALBANIA   \n",
       "10  2023-03-02  20:56:52.4       2.3                    CENTRAL TURKEY   \n",
       "11  2023-03-02  20:55:28.8       5.0                           VANUATU   \n",
       "12  2023-03-02  20:52:01.6       2.3                    CENTRAL TURKEY   \n",
       "13  2023-03-02  20:37:10.6       2.2                    CENTRAL TURKEY   \n",
       "14  2023-03-02  20:25:10.0       3.6                       MOLUCCA SEA   \n",
       "15  2023-03-02  20:22:46.8       2.5                    CENTRAL TURKEY   \n",
       "16  2023-03-02  20:22:02.0       3.8                       MOLUCCA SEA   \n",
       "17  2023-03-02  20:16:45.1       3.9                    CENTRAL TURKEY   \n",
       "18  2023-03-02  20:11:50.1       2.7                    CENTRAL TURKEY   \n",
       "19  2023-03-02  20:00:02.5       5.0                SANTA CRUZ ISLANDS   \n",
       "\n",
       "   latitude longitude  \n",
       "0   38.34 N   27.17 E  \n",
       "1   19.39 N  155.48 W  \n",
       "2   22.28 N  102.28 E  \n",
       "3   37.39 N   36.90 E  \n",
       "4   38.99 N   27.85 E  \n",
       "5   37.48 N   37.13 E  \n",
       "6   38.79 N  122.78 W  \n",
       "7   38.83 N  122.70 W  \n",
       "8    3.35 S  128.35 E  \n",
       "9   41.36 N   19.59 E  \n",
       "10  37.99 N   36.42 E  \n",
       "11  14.86 S  166.88 E  \n",
       "12  38.16 N   37.89 E  \n",
       "13  37.61 N   37.19 E  \n",
       "14   2.91 N  127.42 E  \n",
       "15  38.12 N   37.86 E  \n",
       "16   0.29 N  125.74 E  \n",
       "17  38.03 N   36.65 E  \n",
       "18  38.09 N   37.89 E  \n",
       "19  11.97 S  166.05 E  "
      ]
     },
     "execution_count": 1607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"latitude\"]= data[2] + \" \" + data[3]\n",
    "data[\"longitude\"]= data[4] + \" \" + data[5]\n",
    "data=data.drop([2,3,4,5], axis=1)\n",
    "data=data.set_axis(['date', 'time','magnitude','region', 'latitude', 'longitude'], axis=1)\n",
    "data=data[0:20]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1608,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all language names and number of related articles in the order they appear in wikipedia.org: \n",
    "url = 'https://www.wikipedia.org/'\n",
    "wikipedia = requests.get(url).content\n",
    "soup = BeautifulSoup(wikipedia, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1609,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = soup.find_all('strong')\n",
    "articles =  soup.select('small>bdi') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1610,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [i.get_text() for i in languages] \n",
    "languages.pop(0)\n",
    "languages.pop(10)\n",
    "languages=pd.DataFrame(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 1611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [i.get_text() for i in articles]\n",
    "articles=pd.DataFrame(articles)\n",
    "type(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1612,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia=np.concatenate([languages, articles], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idioma</th>\n",
       "      <th>languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>6 606 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Русский</td>\n",
       "      <td>1 887 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>日本語</td>\n",
       "      <td>1 359 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deutsch</td>\n",
       "      <td>2 764 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Français</td>\n",
       "      <td>2 488 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Español</td>\n",
       "      <td>1 833 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Italiano</td>\n",
       "      <td>1 792 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中文</td>\n",
       "      <td>1 331 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>فارسی</td>\n",
       "      <td>947 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Polski</td>\n",
       "      <td>1 552 000+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idioma   languages\n",
       "0   English  6 606 000+\n",
       "1   Русский  1 887 000+\n",
       "2       日本語  1 359 000+\n",
       "3   Deutsch  2 764 000+\n",
       "4  Français  2 488 000+\n",
       "5   Español  1 833 000+\n",
       "6  Italiano  1 792 000+\n",
       "7        中文  1 331 000+\n",
       "8     فارسی    947 000+\n",
       "9    Polski  1 552 000+"
      ]
     },
     "execution_count": 1613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia=pd.DataFrame(wikipedia)\n",
    "wikipedia=wikipedia.set_axis(['idioma', 'languages'], axis=1)\n",
    "wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1614,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list with the different kind of datasets available in data.gov.uk:\n",
    "url = 'https://data.gov.uk/'\n",
    "datasets = requests.get(url).content\n",
    "soup = BeautifulSoup(datasets, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business and economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crime and justice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Defence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Government spending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Towns and cities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Digital service performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Government reference data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       datasets\n",
       "0          Business and economy\n",
       "1             Crime and justice\n",
       "2                       Defence\n",
       "3                     Education\n",
       "4                   Environment\n",
       "5                    Government\n",
       "6           Government spending\n",
       "7                        Health\n",
       "8                       Mapping\n",
       "9                       Society\n",
       "10             Towns and cities\n",
       "11                    Transport\n",
       "12  Digital service performance\n",
       "13    Government reference data"
      ]
     },
     "execution_count": 1615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets=soup.select('h3>a')\n",
    "datasets = [i.get_text() for i in datasets ]\n",
    "datasets = pd.DataFrame({\"datasets\": datasets})\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 languages by number of native speakers stored in a pandas dataframe:\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "speakers = requests.get(url).content\n",
    "soup =  BeautifulSoup (speakers,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1617,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers=soup.find_all('td')\n",
    "speakers = [i.get_text() for i in speakers]\n",
    "speakers=speakers[0:108]\n",
    "languages=speakers[::4]\n",
    "num_speakers = speakers[1::4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1618,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers=pd.DataFrame({'languages': languages,\n",
    "                       'num_speakers': num_speakers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>languages</th>\n",
       "      <th>num_speakers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mandarin Chinese(incl. Standard Chinese, but e...</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi(excl. Urdu)</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bengali</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russian</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yue Chinese(incl. Cantonese)</td>\n",
       "      <td>86.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wu Chinese(incl. Shanghainese)</td>\n",
       "      <td>83.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Marathi</td>\n",
       "      <td>83.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Telugu</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Korean</td>\n",
       "      <td>81.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>French</td>\n",
       "      <td>80.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tamil</td>\n",
       "      <td>78.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Egyptian Spoken Arabic(excl. Saʽidi Arabic)</td>\n",
       "      <td>77.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Standard German</td>\n",
       "      <td>75.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Urdu(excl. Hindi)</td>\n",
       "      <td>70.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Javanese</td>\n",
       "      <td>68.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Western Punjabi(excl. Eastern Punjabi)</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Italian</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gujarati</td>\n",
       "      <td>57.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Iranian Persian(excl. Dari and Tajik)</td>\n",
       "      <td>57.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Bhojpuri</td>\n",
       "      <td>52.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hausa</td>\n",
       "      <td>51.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            languages num_speakers\n",
       "0   Mandarin Chinese(incl. Standard Chinese, but e...          939\n",
       "1                                             Spanish          485\n",
       "2                                             English          380\n",
       "3                                   Hindi(excl. Urdu)          345\n",
       "4                                          Portuguese          236\n",
       "5                                             Bengali          234\n",
       "6                                             Russian          147\n",
       "7                                            Japanese          123\n",
       "8                        Yue Chinese(incl. Cantonese)         86.1\n",
       "9                                          Vietnamese         85.0\n",
       "10                                            Turkish         84.0\n",
       "11                     Wu Chinese(incl. Shanghainese)         83.4\n",
       "12                                            Marathi         83.2\n",
       "13                                             Telugu         83.0\n",
       "14                                             Korean         81.7\n",
       "15                                             French         80.8\n",
       "16                                              Tamil         78.6\n",
       "17        Egyptian Spoken Arabic(excl. Saʽidi Arabic)         77.4\n",
       "18                                    Standard German         75.3\n",
       "19                                  Urdu(excl. Hindi)         70.6\n",
       "20                                           Javanese         68.3\n",
       "21             Western Punjabi(excl. Eastern Punjabi)         66.7\n",
       "22                                            Italian         64.6\n",
       "23                                           Gujarati         57.1\n",
       "24              Iranian Persian(excl. Dari and Tajik)         57.2\n",
       "25                                           Bhojpuri         52.3\n",
       "26                                              Hausa         51.7"
      ]
     },
     "execution_count": 1619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers=speakers.replace({'\\n':\"\"}, regex=True)\n",
    "speakers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6a2100a7efc7529035a40d3ea72bc8e547ceb70664fb95a465d233cbcc6110c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
